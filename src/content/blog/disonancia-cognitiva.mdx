---
title: "Disonancia cognitiva"
description: "Cuando la evidencia duele: disonancia cognitiva y pensamiento estadístico"
pubDate: "Sep 03 2025"
topic: "Disonancia"
tags: ["disonancia cognitiva", "estadística", "sesgos", "metaciencia", "antropología del cerebro", "exocerebro", "evidencia"]
draft: false
lang: "es"
heroImage: '../../assets/post/disonancia1.png'
---
import { Image } from 'astro:assets';
import dis2 from '../../assets/post/disonancia2.png';
import dis3 from '../../assets/post/disonancia3.png';
import dis4 from '../../assets/post/disonancia4.png';

Desde que empecé como programador, solía interactuar con perfiles muy distintos para debatir **monolito vs. microservicios** y **sincronía vs. colas**. En esas discusiones me topé con el concepto de “**disonancia cognitiva**”. Lo primero que pensé fue: “esto a mí no me pasa; yo me baso en datos”. **Nada más lejos de la realidad.**

Al profundizar en lo que implicaba la disonancia, empecé intuitivamente a hacer **calibraciones** del tipo: “estoy un 80% seguro de X”, “estoy un 95% seguro de B”, y pasé a incorporar **calibración por rangos** —usando bandas: **40-60** incierto, **60-80** probable, **80-95** muy probable—.

Poco después, tras cada reunión **revisaba** qué había pasado; creyéndome libre de toda disonancia, caí múltiples veces. Aun así, **seguí gestionando** esa tendencia, porque es **intrínseca** a cómo funciona nuestro **cerebro** y no es más que otro mecanismo de supervivencia; **lo que empecé a aplicar no eliminó la fricción, pero mejoró el coste esperado de una mala decisión**.

<figure style={{ margin: '2rem auto', textAlign: 'center'}}>
  <Image
    src={dis2}
    alt="Viñeta con bifurcación: a la izquierda 'Reduce dissonance' con nubes 'Ad hoc' y 'Post hoc'; a la derecha 'Update beliefs' con un ciclo 'Question → Data → Model → Test'."
    quality={70}
    loading="lazy"
    decoding="async"
    style={{ display: 'block', margin: '0 auto', borderRadius: '12px' }}
  />
  <figcaption style={{ marginTop: '0.5rem', color: 'var(--font-color-normal)' }}>
    Dos caminos ante el conflicto entre ideas
  </figcaption>
</figure>

# 1. Contexto
- **Disonancia cognitiva (Festinger, 1957):** cuando dos cognición chocan, surge tensión psicológica y una **búsqueda de coherencia** que intentamos satisfacer (cambiando creencias, buscando apoyo selectivo, evitando información disonante).
- **Cerebro, cultura y símbolos (Bartra):** la mente no vive aislada en el cráneo; se apoya en sistemas simbólicos y soportes externos (*exocerebro*). La evaluación de evidencia es una práctica cultural, no solo neuronal.
- **Problema actual:** estamos rodeados de informaciones contradictorias -a menudo de baja fiabilidad- que resuenan con nuestra coherencia interna, además de cámaras de eco y racionalizaciones.

# 2. Estrategias defensivas frente a la disonancia cognitiva
Uno de los textos más reveladores que leí fue la **Teoría de la disonancia cognitiva**, de Leon Festinger.

Me permitió entender cómo una idea nueva, que contradice de alguna forma nuestras creencias o supuestos previos, puede generar una incomodidad profunda: **nos desafía porque amenaza la coherencia interna con la que sostenemos nuestra visión del mundo**.

Ante esa incomodidad, solemos activar una serie de **estrategias defensivas**. Son mecanismos mentales que nos ayudan a reducir la tensión sin tener que revisar lo que creemos. Algunas de ellas son sutiles; otras, radicales.

Veamos algunas de las más comunes:

- **Reinterpretación:** modificamos los términos o el contexto de la nueva información para que pueda **encajar en nuestro sistema de creencias**, sin tocar el núcleo de lo que ya creemos.

    > _“Cuando dijo que el talento no importa tanto, seguro que se refería a casos extremos.”_
    
    Señales observables:
    - Cambios de definición _a posteriori_ (“por talento quería decir disciplina”).
    - Calificativos que suavizan: “en realidad…”, “en este contexto…”.
    - Excepciones *ad hoc* añadidas tras ver el dato.
    - Reetiquetar la evidencia: “no es fallo, es comportamiento esperado”.
    - Cambios de marco (población/caso de referencia) durante la discusión.
    
- **Devaluación de la fuente:** aplicamos una **falacia** *ad hominem*: en lugar de analizar el argumento, atacamos a la persona que lo dice. Cuestionamos su autoridad, su intención o incluso su carácter, con tal de preservar intactas nuestras ideas.
    
    > _“¿Qué va a saber él? Si ni siquiera ha trabajado en el sector.”_
    
    Señales observables:
    - Preguntar primero **quién** lo dice antes de **qué** datos presenta.
    - **Credencialismo** selectivo (exigir títulos a unos y no a otros).
    - Atribuir intención/agenda (“**viene a vendernos X**”) en vez de evaluar evidencia.
    - **Aceptar/rechazar** el mismo argumento si lo dice alguien del grupo y rechazarlo si viene de fuera.
    - **Citar errores pasados** irrelevantes para desestimar el argumento actual.
    
- **Búsqueda selectiva (sesgo de confirmación):** nos exponemos solo a información que **refuerza lo que ya pensamos** y evitamos datos que podrían contradecirlo. Vivimos en una burbuja cognitiva.
    
    > _“Este artículo dice justo lo que yo siempre he defendido. No necesito leer el otro.”_
    
    Señales observables:
    - *Feeds*/listas de lectura **homogéneos;** dejar de seguir fuentes disonantes.
    - Cierre de pestañas “contrarias” sin lectura o con **lectura superficial**.
    - Marcadores/Notion/RFCs solo con piezas alineadas; **sin** contrapruebas.
    - Experimentos diseñados para **confirmar**, no para **falsar** hipótesis.
    - Reuniones donde **no se invita** a la parte crítica/afectada.
    
- **Evitación:** directamente **desconectamos del tema**. Evitamos noticias, conversaciones o entornos que puedan activar la disonancia. Cuanto más amenazante parezca la información, mayor es el deseo de evitarla.
    
    Señales observables:
    - Cambiar de tema cuando aparecen **métricas incómodas** (churn, p95, 5xx).
    - **Postergar** _sine die_ revisiones/retros con contraevidencia.
    - **Cancelar entrevistas** de usuarios críticos; “no hay tiempo para research”.
    - Reacciones emocionales **desproporcionadas** ante datos que contradicen.
    - “Luego lo miro” sistemático respecto a informes que no encajan.

# 3. El ciclo de la información (o proceso disonante)
<figure style={{ margin: '2rem auto', textAlign: 'center'}}>
    <Image
        src={dis3}
        alt="Disonancia y ciclo de la información"
        quality={70}
        loading="lazy"
        decoding="async"
        style={{ display: 'block', margin: '0 auto', borderRadius: '12px' }}
    />
    <figcaption style={{ marginTop: '0.5rem', color: 'var(--font-color-normal)' }}>
        Ciclo de la información
    </figcaption>
</figure>

Me fascina el funcionamiento de nuestra mente, sobre todo cuando se enfrenta a información nueva. Podemos pensar en **la información no como un dato neutro**, sino como algo que **atraviesa un ciclo psicológico**: antes de exponernos a ella, durante su procesamiento y después de consumirla.

En cada etapa, nuestros sesgos y mecanismos de defensa cognitivos activan **una tensión entre coherencia e incomodidad**.
### Antes de recibirla: filtrado anticipado
Vivimos expuestos a una infinidad de estímulos. Pero **no los procesamos todos por igual**. De hecho, tendemos a **filtrar de antemano** la información que intuimos como disonante.

- Preferimos titulares que suenen coherentes, aunque la fuente sea dudosa.
- Ignoramos activamente aquello que podría sacudir nuestras certezas.
- Buscamos, sin darnos cuenta, confirmar lo que ya creemos.

> _La información que nunca llega a nosotros es, muchas veces, la más necesaria para crecer._

**Señales:** titulares “que encajan”, bloqueo de fuentes disonantes, listas homogéneas.
**Acción:** Regla de 3 fuentes antes de opinar.
**Ritual:** checklist: independencia / método / formato.
### Mientras la consumimos: atención sesgada
- Prestamos más atención a los argumentos que refuerzan lo que ya pensamos.
- Descartamos rápidamente las ideas que nos incomodan.
- Juzgamos a la fuente si lo que dice no encaja con nuestra narrativa.

> _No estamos buscando entender: estamos buscando confirmar._

**Señales:** subrayas confirmaciones, descartas rápido lo incómodo, te vas al “quién” antes que al “qué”.
**Acción:** doble columna resuena (1-5) / es fiable (1-5), integrar solo si ≥3/5 en ambos.
**Ritual:** _steelman_ del argumento contrario en 3 bullets antes de decidir.
### Después de consumirla: cierre cognitivo
Una vez expuestos a la información, se activa el último tramo del ciclo: **asimilarla sin desestabilizar nuestra identidad**.

Aquí aparecen tres mecanismos comunes:
- **Cierre prematuro:** recordamos solo lo que confirma nuestras ideas; la contraevidencia se ignora o se reetiqueta como “caso aislado”.
- **Escalada de compromiso:** tras comprometernos públicamente con una idea, cambiarla se vuelve más difícil porque ya hemos invertido reputación.
- **Reescritura retrospectiva:**
    
    > “Yo ya sabía esto, solo que no lo había dicho así.”
    
    > Genera coherencia retrospectiva, pero **empobrece el aprendizaje**: si siempre “ya lo sabías”, nunca cambias nada.
    
**Señales:** recuerdas solo confirmaciones, mueves criterios tras ver resultados, narrativa _post hoc_.
**Acción:** bitácora antes/después + reglas si-entonces + stop-loss cognitivo (cuándo revertir).
**Ritual:** registro: fecha - señal - ajuste - nuevo rango de probabilidad.

Este sesgo de procesamiento explica por qué dos personas pueden leer el mismo artículo y llegar a **conclusiones opuestas**. Para evitarlo, instalamos puertas de control en cada fase.

# 4. Pensamiento estadístico como antídoto
El **propósito** de un intercambio de información, ya sea mediante una conversación o una **búsqueda exhaustiva**, **no** es _ganar_ ni “tener razón”, sino **mejorar nuestro modelo de la realidad**: reconciliar lo que ya creemos (coherencia interna) con lo que muestran los datos, la experiencia o el contexto (mundo externo). Verás 2-3 micro-rituales aplicables hoy.

En la práctica tenemos tres pasos
- **Evaluar** una idea en dos ejes:
    - **Encaje** con tu marco (1-5: 1=rompe, 3=mixto, 5=refuerza).
    - **Fiabilidad** de la evidencia (1-5: 1=rumor, 3=datos preliminares, 5=convergencia independiente).
- **Decidir**:
    - **Integrar** si **fiabilidad≥3/5** **y** **encaje≥4/5** (p. ej., datos sólidos y mejoras claras de coherencia). 
    - **Aparcar/refutar provisionalmente** si **fiabilidad más grande que 3/5** **o** **encaje=1/5**, aunque “resuene”.
- **Actualizar** tu marco: deja rastro de **qué cambió y por qué**.
    - **Bitácora** (formato mínimo): fecha - señal - decisión - regla si-entonces - nuevo rango (%).

Cuando estemos en medio de una conversación, consumiendo contenido o intentando llegar a un **acuerdo**, conviene recordar que el pensamiento **no tiene por qué** ser **dicotómico**, aunque genere **incomodidad**: un **argumento** puede tener **grados de certeza** y de incorporación a nuestro sistema de creencias.  Por ejemplo: 70% de que la reunión sea útil; si enviamos agenda y objetivos 24h antes → +10 pp; si no hay moderador → -10 pp.

Podríamos expresar esta creencia a la cual estamos expuestos en cuatro **intervalos** 0-25% muy improbable,  25-50% poco probable, 50-75% probable, 75-100% muy probable en vez de **aceptarlo o descartarlo**, por lo que ese argumento no será eliminado sino que tendrá un peso determinado.

Podemos usar esta **estrategia** para **justificar** nuestra creencia y mantener la coherencia entre las ideas. **Sin embargo, sin reglas previas, las bandas se vuelven performativas:** terminan defendiendo una postura en lugar de favorecer el aprendizaje.

En cualquier caso, estos grados pueden cambiar el intervalo de certeza: **si ocurre X, el argumento A subirá 10% y pasará al intervalo de “probable”**.

Aun adoptando el sistema de grados, podemos forzar el sistema para aun asi, mantener nuestras creencias intactas:

* Inflar/deflactar puntuaciones sin base (ajustarlas al alza o a la baja para que cuadren con la tesis propia).
* Comparar la idea con casos extremos o no representativos para rebajar su peso. Contramedida: fija población, ventana y métrica antes de evaluar (criterios previos por escrito).
* Bitácora del coste esperado (impacto × probabilidad) de adoptar/rechazar la novedad y de las decisiones que hemos ido tomando; registra: fecha - señal - decisión - regla si-entonces - nuevo rango (%).

# 5. Contramedidas: la guerra contra la coherencia
1. **“Mi argumento no puede estar mal.”**
    **Mecanismo:** amenaza a la identidad → **disonancia** alta → racionalizaciones (“la fuente falla”, “ese caso no cuenta”).
    **Contramedida:** **acero y paja** (*steelman / strawman*): reconstruye el **mejor** argumento contrario y el **peor** del propio, y júzgalos con **el mismo criterio**.
    **Ritual:** escribe en 3 *bullets* el *steelman* rival y en 3 bullets tu *strawman*; decide qué dato falsaría a cada uno.
    
2. **“La nueva explicación no encaja en todos los casos.”**
    **Mecanismo:** perfeccionismo de encaje; un contraejemplo local dispara el descarte global.
    **Contramedida:** **condicionaliza**: explicita **dónde sí / dónde no**; dibuja un mapa **si-entonces** con límites de validez.
    **Ritual:** 3 filas: “si [condición] → aplica / no aplica / requiere ajuste”.
    
3. **“Ya lo sabía.”** (reescritura retrospectiva)
    **Mecanismo:** edición del pasado para preservar coherencia temporal.
    **Contramedida:** **registro antes/después** con fecha; normaliza **pequeños cambios** como progreso, no derrota.
    **Ritual:** una línea de *changelog*: fecha - señal - ajuste - nuevo rango/tesis.
    
4. **“No me expongo a X.”** (cámara de eco)
    **Mecanismo:** evitación selectiva para reducir disonancia.
    **Contramedida:** **regla de 3 fuentes**: al menos tres **independientes** y de **formatos distintos** (ensayo, testimonio, análisis).
    **Ritual:** *checklist*: 1) independencia, 2) método explícito, 3) formato distinto.
    
5. **“No es comparable.”** (excepción *ad hoc*)
    **Mecanismo:** mover el criterio de comparación según conviene.
    **Contramedida:** matriz **igual / similar / distinto** + **criterios fijos** definidos **antes** del caso.
    **Ritual:** define 3 criterios (p. ej., población, métrica, ventana temporal) y clasifica el caso en la matriz.
    
6. **“Traes rumores, pero me cuadran.”** (resonancia sin fiabilidad)
    **Mecanismo:** la coherencia subjetiva **maquilla** baja calidad informativa.
    **Contramedida:** doble columna **“resuena / es fiable”** y **umbral mínimo en ambos** para integrar una idea.
    **Ritual:** puntúa 1-5 en cada eje; solo integras si ≥3/5 en **ambos**.

# 6. Casos y ejemplos actuales: estrategias

<figure className="floatRight">
    <Image
        src={dis4}
        alt="Disonancia y ciclo de la información"
        quality={70}
        loading="lazy"
        decoding="async"
        style={{ display: 'block', margin: 0, borderRadius: '12px', width: '100%', height: 'auto' }}
    />
    <figcaption>Ciclo de la información</figcaption>

    <style jsx>{`
        .floatRight {
            float: right;
            width: min(340px, 40%);
            margin: 0 0 1rem 1rem; /* separa del texto: arriba/dcha/abajo/izda */
            text-align: center;
            color: var(--font-color-normal);
        }
        @media (max-width: 768px) {
            .floatRight {
                float: none;
                width: 100%;
                margin: 1rem 0;
            }
        }
    `}</style>
</figure>


**Objetivo común:** transformar la disonancia originada por **informaciones contradictoria** (a menudo **poco fiables**) que **resuenan** con nuestra coherencia en **decisiones más sólidas** mediante **rituales de coherencia** (precompromisos, historias rivales, actualización antes/después, doble columna resuena/fiable), sin depender de **métricas** ni *dashboards*.

### Experimentos con fricción útil en producto
- **Precompromiso**: formular la **pregunta decisiva** y el si-entonces: “Si observamos señales **(S1 y S2)** (cualitativas y trazables), **integramos** la novedad; si aparecen **(R1 o R2)** (riesgos/daños), **revertimos**”.
    - **p. ej.:** Si (abandono en “verificación” baja **20% relativo** en 2 sprints **y** 5/10 entrevistas mencionan menor confusión) → **integrar**; si (tickets “no entiendo la verificación” **≥5/semana** durante 2 semanas **o** tasa de errores **>1% por transacción** durante 7 días) → **revertir**.
	
- **Historias rivales:** redactar la **mejor** versión del argumento a favor y en contra; **antes de debatir, fija por escrito criterios simétricos** para ambos (p. ej., **población**, **métrica**, **ventana temporal**, **umbral de éxito**, **horizonte de revisión**, **riesgos aceptables**).

- **Señales de activación** (no numéricas): ejemplos de comportamientos de usuario, objeciones en soporte, patrones de abandono narrados, fricciones recurrentes en entrevistas.
	- Usuarios dicen “no entiendo la verificación” al abandonar ese paso.
	- En soporte aparece repetido “no encuentro dónde cambiar la contraseña”.
	
- **Ventana de revisión**: fecha fija (p. ej., 2 semanas) para evaluar **antes/después** por escrito.

### Post-mortems sin culpa
- **Separación de planos**: (a) _qué cambió_ (hechos narrables/trazables); (b) _por qué decidimos así_(contexto/limitaciones); (c) _qué actualizar_ (reglas, diccionario de términos, criterios si-entonces).
- **Registro de contraevidencia**: lista de piezas que **no encajan** pero podrían indicar aprendizaje; asignar responsables de seguimiento.
- **Lenguaje de actualización**: “A la luz de X e Y, **actualizamos** Z; si aparece W, **revisamos** de nuevo”.

### Decisiones de arquitectura

- **Riesgo de disonancia**: la opción que **resuena** con la identidad del equipo ("somos *microservices*" / "aquí todo es síncrono por simplicidad") puede imponerse pese a **señales contradictorias** del contexto.
- **Ritual**: **RFC con** *steelman* de la alternativa descartada; **criterios invariantes** definidos antes de debatir (acoplamiento real, límites de dominio, ritmo de entrega, capacidad operativa, radio de fallo, latencia de extremo a extremo). **Precompromiso** con mapa si-entonces y **stop-loss cognitivo**.
- **Señales S (integrar)**: menos *handoffs* entre equipos, despliegues más simples, límites de contexto estables, menor coordinación para cambios pequeños.
- **Señales R (revisar/revertir)**: **creep** de dependencias cruzadas, cascadas de fallos, coordinación creciente por cambios pequeños, proliferación de excepciones *ad hoc*.

### Priorización de backlog con señales contradictorias
- **Caso**: “este _feature_ es **clave** para *enterprise*” (rumor que **cuadra** pero es poco fiable).
- **Ritual**: **regla de 3 fuentes** (ventas, soporte, investigación de usuario) + **entrevistas rápidas** (5 clientes) con *steelman* de la objeción; **contrafactual mínimo viable**: ¿qué pasa si _no_ lo hacemos 2 sprints?
- **Decisión condicional**: si aparecen S1/S2 (patrones de abandono narrados, objeciones repetidas trazables), **integrar**; si no, **posponer** y revisar fecha.

###  Code review: preferencias identitarias vs. criterio técnico
- **Riesgo**: confundir **gusto** con **criterio** (p. ej., estilo de framework vs. claridad/seguridad).
- **Ritual**: plantilla de PR con tres bloques: (a) **riesgo adverso** contemplado, (b) **qué cambiaría** mi opinión, (c) *steelman* de la alternativa. **Semáforo de afirmaciones** (verde=hecho trazable, ámbar=inferencia, rojo=rumor/coherencia sin base). **Doble columna** _resuena / es fiable_.

# 7.  Fuentes y lecturas recomendadas
- Festinger, L. _Teoría de la disonancia cognoscitiva_ (1957).
- Bartra, R. _Antropología del cerebro: conciencia, cultura y libre albedrío_ (2014).
- Gelman, A. & Loken, E. _The garden of forking paths_ (ensayo sobre decisiones analíticas y significación).
- Kahneman, D. _Thinking, Fast and Slow_ (visiones prácticas sobre sesgos e incertidumbre).
- McElreath, R. _Statistical Rethinking_ (enfoque aplicado y explícito sobre incertidumbre y actualización).
