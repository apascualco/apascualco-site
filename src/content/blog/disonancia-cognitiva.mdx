---
title: 'Disonancia cognitiva'
description: 'Cuando la evidencia duele: disonancia cognitiva y pensamiento estadístico'
pubDate: 'Sep 03 2025'
topic: 'Disonancia'
tags:
  [
    'disonancia cognitiva',
    'sesgos cognitivos',
    'pensamiento estadístico',
    'toma de decisiones',
    'pensamiento crítico',
    'psicología cognitiva',
    'racionalidad',
  ]
draft: false
lang: 'es'
heroImage: '../../assets/post/disonancia1.png'
---

import { Image } from 'astro:assets';
import dis2 from '../../assets/post/disonancia2.png';
import dis3 from '../../assets/post/disonancia3.png';
import dis4 from '../../assets/post/disonancia4.png';

### Índice

1. [Contexto](#1-contexto)
2. [Estrategias defensivas frente a la disonancia cognitiva](#2-estrategias-defensivas-frente-a-la-disonancia-cognitiva)
3. [El ciclo de la información (o proceso disonante)](#3-el-ciclo-de-la-información-o-proceso-disonante)
4. [Pensamiento estadístico como antídoto](#4-pensamiento-estadístico-como-antídoto)
5. [Contramedidas: la guerra contra la coherencia](#5-contramedidas-la-guerra-contra-la-coherencia)
6. [Casos y ejemplos actuales: estrategias](#6-casos-y-ejemplos-actuales-estrategias)
7. [Fuentes y lecturas recomendadas](#7-fuentes-y-lecturas-recomendadas)

Desde que empecé como programador, solía interactuar con perfiles muy distintos para debatir **monolito vs. microservicios** y **sincronía vs. colas**. En esas discusiones me topé con el concepto de “**disonancia cognitiva**”. Lo primero que pensé fue: “esto a mí no me pasa; yo me baso en datos”. **Nada más lejos de la realidad.**

Al profundizar en lo que implicaba la disonancia, empecé intuitivamente a hacer **calibraciones** del tipo: “estoy un 80% seguro de X”, “estoy un 95% seguro de B”, y pasé a incorporar **calibración por rangos** —usando bandas: **40-60** incierto, **60-80** probable, **80-95** muy probable—.

Poco después, tras cada reunión **revisaba** qué había pasado; creyéndome libre de toda disonancia, caí múltiples veces. Aun así, **seguí gestionando** esa tendencia, porque es **intrínseca** a cómo funciona nuestro **cerebro** y no es más que otro mecanismo de supervivencia; **lo que empecé a aplicar no eliminó la fricción, pero mejoró el coste esperado de una mala decisión**.

<figure style={{ margin: '2rem auto', textAlign: 'center' }}>
  <Image
    src={dis2}
    alt="Viñeta con bifurcación: a la izquierda 'Reduce dissonance' con nubes 'Ad hoc' y 'Post hoc'; a la derecha 'Update beliefs' con un ciclo 'Question → Data → Model → Test'."
    quality={70}
    loading="lazy"
    decoding="async"
    style={{ display: 'block', margin: '0 auto', borderRadius: '12px' }}
  />
  <figcaption style={{ marginTop: '0.5rem', color: 'var(--font-color-normal)' }}>
    Dos caminos ante el conflicto entre ideas
  </figcaption>
</figure>

# 1. Contexto

- **Disonancia cognitiva (Festinger, 1957):** cuando dos cognición chocan, surge tensión psicológica y una **búsqueda de coherencia** que intentamos satisfacer (cambiando creencias, buscando apoyo selectivo, evitando información disonante).
- **Cerebro, cultura y símbolos (Bartra):** la mente no vive aislada en el cráneo; se apoya en sistemas simbólicos y soportes externos (_exocerebro_). La evaluación de evidencia es una práctica cultural, no solo neuronal.
- **Problema actual:** estamos rodeados de informaciones contradictorias -a menudo de baja fiabilidad- que resuenan con nuestra coherencia interna, además de cámaras de eco y racionalizaciones.

# 2. Estrategias defensivas frente a la disonancia cognitiva

Uno de los textos más reveladores que leí fue la **Teoría de la disonancia cognitiva**, de Leon Festinger.

Me permitió entender cómo una idea nueva, que contradice de alguna forma nuestras creencias o supuestos previos, puede generar una incomodidad profunda: **nos desafía porque amenaza la coherencia interna con la que sostenemos nuestra visión del mundo**.

Ante esa incomodidad, solemos activar una serie de **estrategias defensivas**. Son mecanismos mentales que nos ayudan a reducir la tensión sin tener que revisar lo que creemos. Algunas de ellas son sutiles; otras, radicales.

Veamos algunas de las más comunes:

- **Reinterpretación:** modificamos los términos o el contexto de la nueva información para que pueda **encajar en nuestro sistema de creencias**, sin tocar el núcleo de lo que ya creemos.

  > _“Cuando dijo que el talento no importa tanto, seguro que se refería a casos extremos.”_

  Señales observables:
  - Cambios de definición _a posteriori_ (“por talento quería decir disciplina”).
  - Calificativos que suavizan: “en realidad…”, “en este contexto…”.
  - Excepciones _ad hoc_ añadidas tras ver el dato.
  - Reetiquetar la evidencia: “no es fallo, es comportamiento esperado”.
  - Cambios de marco (población/caso de referencia) durante la discusión.

- **Devaluación de la fuente:** aplicamos una **falacia** _ad hominem_: en lugar de analizar el argumento, atacamos a la persona que lo dice. Cuestionamos su autoridad, su intención o incluso su carácter, con tal de preservar intactas nuestras ideas.
  > _“¿Qué va a saber él? Si ni siquiera ha trabajado en el sector.”_
  > Señales observables:
  - Preguntar primero **quién** lo dice antes de **qué** datos presenta.
  - **Credencialismo** selectivo (exigir títulos a unos y no a otros).
  - Atribuir intención/agenda (“**viene a vendernos X**”) en vez de evaluar evidencia.
  - **Aceptar/rechazar** el mismo argumento si lo dice alguien del grupo y rechazarlo si viene de fuera.
  - **Citar errores pasados** irrelevantes para desestimar el argumento actual.
- **Búsqueda selectiva (sesgo de confirmación):** nos exponemos solo a información que **refuerza lo que ya pensamos** y evitamos datos que podrían contradecirlo. Vivimos en una burbuja cognitiva.
  > _“Este artículo dice justo lo que yo siempre he defendido. No necesito leer el otro.”_
  > Señales observables:
  - _Feeds_/listas de lectura **homogéneos;** dejar de seguir fuentes disonantes.
  - Cierre de pestañas “contrarias” sin lectura o con **lectura superficial**.
  - Marcadores/Notion/RFCs solo con piezas alineadas; **sin** contrapruebas.
  - Experimentos diseñados para **confirmar**, no para **falsar** hipótesis.
  - Reuniones donde **no se invita** a la parte crítica/afectada.
- **Evitación:** directamente **desconectamos del tema**. Evitamos noticias, conversaciones o entornos que puedan activar la disonancia. Cuanto más amenazante parezca la información, mayor es el deseo de evitarla.
  Señales observables:
  - Cambiar de tema cuando aparecen **métricas incómodas** (churn, p95, 5xx).
  - **Postergar** _sine die_ revisiones/retros con contraevidencia.
  - **Cancelar entrevistas** de usuarios críticos; “no hay tiempo para research”.
  - Reacciones emocionales **desproporcionadas** ante datos que contradicen.
  - “Luego lo miro” sistemático respecto a informes que no encajan.

# 3. El ciclo de la información (o proceso disonante)

<figure style={{ margin: '2rem auto', textAlign: 'center' }}>
  <Image
    src={dis3}
    alt="Disonancia y ciclo de la información"
    quality={70}
    loading="lazy"
    decoding="async"
    style={{ display: 'block', margin: '0 auto', borderRadius: '12px' }}
  />
  <figcaption style={{ marginTop: '0.5rem', color: 'var(--font-color-normal)' }}>
    Ciclo de la información
  </figcaption>
</figure>

Me fascina el funcionamiento de nuestra mente, sobre todo cuando se enfrenta a información nueva. Podemos pensar en **la información no como un dato neutro**, sino como algo que **atraviesa un ciclo psicológico**: antes de exponernos a ella, durante su procesamiento y después de consumirla.

En cada etapa, nuestros sesgos y mecanismos de defensa cognitivos activan **una tensión entre coherencia e incomodidad**.

### Antes de recibirla: filtrado anticipado

Vivimos expuestos a una infinidad de estímulos. Pero **no los procesamos todos por igual**. De hecho, tendemos a **filtrar de antemano** la información que intuimos como disonante.

- Preferimos titulares que suenen coherentes, aunque la fuente sea dudosa.
- Ignoramos activamente aquello que podría sacudir nuestras certezas.
- Buscamos, sin darnos cuenta, confirmar lo que ya creemos.

> _La información que nunca llega a nosotros es, muchas veces, la más necesaria para crecer._

**Señales:** titulares “que encajan”, bloqueo de fuentes disonantes, listas homogéneas.
**Acción:** Regla de 3 fuentes antes de opinar.
**Ritual:** checklist: independencia / método / formato.

### Mientras la consumimos: atención sesgada

- Prestamos más atención a los argumentos que refuerzan lo que ya pensamos.
- Descartamos rápidamente las ideas que nos incomodan.
- Juzgamos a la fuente si lo que dice no encaja con nuestra narrativa.

> _No estamos buscando entender: estamos buscando confirmar._

**Señales:** subrayas confirmaciones, descartas rápido lo incómodo, te vas al “quién” antes que al “qué”.
**Acción:** doble columna resuena (1-5) / es fiable (1-5), integrar solo si ≥3/5 en ambos.
**Ritual:** _steelman_ del argumento contrario en 3 bullets antes de decidir.

### Después de consumirla: cierre cognitivo

Una vez expuestos a la información, se activa el último tramo del ciclo: **asimilarla sin desestabilizar nuestra identidad**.

Aquí aparecen tres mecanismos comunes:

- **Cierre prematuro:** recordamos solo lo que confirma nuestras ideas; la contraevidencia se ignora o se reetiqueta como “caso aislado”.
- **Escalada de compromiso:** tras comprometernos públicamente con una idea, cambiarla se vuelve más difícil porque ya hemos invertido reputación.
- **Reescritura retrospectiva:**
  > “Yo ya sabía esto, solo que no lo había dicho así.”
  > Genera coherencia retrospectiva, pero **empobrece el aprendizaje**: si siempre “ya lo sabías”, nunca cambias nada.

**Señales:** recuerdas solo confirmaciones, mueves criterios tras ver resultados, narrativa _post hoc_.
**Acción:** bitácora antes/después + reglas si-entonces + stop-loss cognitivo (cuándo revertir).
**Ritual:** registro: fecha - señal - ajuste - nuevo rango de probabilidad.

Este sesgo de procesamiento explica por qué dos personas pueden leer el mismo artículo y llegar a **conclusiones opuestas**. Para evitarlo, instalamos puertas de control en cada fase.

# 4. Pensamiento estadístico como antídoto

El **propósito** de un intercambio de información, ya sea mediante una conversación o una **búsqueda exhaustiva**, **no** es _ganar_ ni “tener razón”, sino **mejorar nuestro modelo de la realidad**: reconciliar lo que ya creemos (coherencia interna) con lo que muestran los datos, la experiencia o el contexto (mundo externo). Verás 2-3 micro-rituales aplicables hoy.

En la práctica tenemos tres pasos

- **Evaluar** una idea en dos ejes:
  - **Encaje** con tu marco (1-5: 1=rompe, 3=mixto, 5=refuerza).
  - **Fiabilidad** de la evidencia (1-5: 1=rumor, 3=datos preliminares, 5=convergencia independiente).
- **Decidir**:
  - **Integrar** si **fiabilidad≥3/5** **y** **encaje≥4/5** (p. ej., datos sólidos y mejoras claras de coherencia).
  - **Aparcar/refutar provisionalmente** si **fiabilidad más grande que 3/5** **o** **encaje=1/5**, aunque “resuene”.
- **Actualizar** tu marco: deja rastro de **qué cambió y por qué**.
  - **Bitácora** (formato mínimo): fecha - señal - decisión - regla si-entonces - nuevo rango (%).

Cuando estemos en medio de una conversación, consumiendo contenido o intentando llegar a un **acuerdo**, conviene recordar que el pensamiento **no tiene por qué** ser **dicotómico**, aunque genere **incomodidad**: un **argumento** puede tener **grados de certeza** y de incorporación a nuestro sistema de creencias. Por ejemplo: 70% de que la reunión sea útil; si enviamos agenda y objetivos 24h antes → +10 pp; si no hay moderador → -10 pp.

Podríamos expresar esta creencia a la cual estamos expuestos en cuatro **intervalos** 0-25% muy improbable, 25-50% poco probable, 50-75% probable, 75-100% muy probable en vez de **aceptarlo o descartarlo**, por lo que ese argumento no será eliminado sino que tendrá un peso determinado.

Podemos usar esta **estrategia** para **justificar** nuestra creencia y mantener la coherencia entre las ideas. **Sin embargo, sin reglas previas, las bandas se vuelven performativas:** terminan defendiendo una postura en lugar de favorecer el aprendizaje.

En cualquier caso, estos grados pueden cambiar el intervalo de certeza: **si ocurre X, el argumento A subirá 10% y pasará al intervalo de “probable”**.

Aun adoptando el sistema de grados, podemos forzar el sistema para aun asi, mantener nuestras creencias intactas:

- Inflar/deflactar puntuaciones sin base (ajustarlas al alza o a la baja para que cuadren con la tesis propia).
- Comparar la idea con casos extremos o no representativos para rebajar su peso. Contramedida: fija población, ventana y métrica antes de evaluar (criterios previos por escrito).
- Bitácora del coste esperado (impacto × probabilidad) de adoptar/rechazar la novedad y de las decisiones que hemos ido tomando; registra: fecha - señal - decisión - regla si-entonces - nuevo rango (%).

# 5. Contramedidas: la guerra contra la coherencia

1. **“Mi argumento no puede estar mal.”**
   **Mecanismo:** amenaza a la identidad → **disonancia** alta → racionalizaciones (“la fuente falla”, “ese caso no cuenta”).
   **Contramedida:** **acero y paja** (_steelman / strawman_): reconstruye el **mejor** argumento contrario y el **peor** del propio, y júzgalos con **el mismo criterio**.
   **Ritual:** escribe en 3 _bullets_ el _steelman_ rival y en 3 bullets tu _strawman_; decide qué dato falsaría a cada uno.
2. **“La nueva explicación no encaja en todos los casos.”**
   **Mecanismo:** perfeccionismo de encaje; un contraejemplo local dispara el descarte global.
   **Contramedida:** **condicionaliza**: explicita **dónde sí / dónde no**; dibuja un mapa **si-entonces** con límites de validez.
   **Ritual:** 3 filas: “si [condición] → aplica / no aplica / requiere ajuste”.
3. **“Ya lo sabía.”** (reescritura retrospectiva)
   **Mecanismo:** edición del pasado para preservar coherencia temporal.
   **Contramedida:** **registro antes/después** con fecha; normaliza **pequeños cambios** como progreso, no derrota.
   **Ritual:** una línea de _changelog_: fecha - señal - ajuste - nuevo rango/tesis.
4. **“No me expongo a X.”** (cámara de eco)
   **Mecanismo:** evitación selectiva para reducir disonancia.
   **Contramedida:** **regla de 3 fuentes**: al menos tres **independientes** y de **formatos distintos** (ensayo, testimonio, análisis).
   **Ritual:** _checklist_: 1) independencia, 2) método explícito, 3) formato distinto.
5. **“No es comparable.”** (excepción _ad hoc_)
   **Mecanismo:** mover el criterio de comparación según conviene.
   **Contramedida:** matriz **igual / similar / distinto** + **criterios fijos** definidos **antes** del caso.
   **Ritual:** define 3 criterios (p. ej., población, métrica, ventana temporal) y clasifica el caso en la matriz.
6. **“Traes rumores, pero me cuadran.”** (resonancia sin fiabilidad)
   **Mecanismo:** la coherencia subjetiva **maquilla** baja calidad informativa.
   **Contramedida:** doble columna **“resuena / es fiable”** y **umbral mínimo en ambos** para integrar una idea.
   **Ritual:** puntúa 1-5 en cada eje; solo integras si ≥3/5 en **ambos**.

# 6. Casos y ejemplos actuales: estrategias

<figure class="floatRight">
  <Image
    src={dis4}
    alt="Disonancia y ciclo de la información"
    quality={70}
    loading="lazy"
    decoding="async"
  />
  <figcaption>Ciclo de la información</figcaption>
</figure>

**Objetivo común:** transformar la disonancia originada por **informaciones contradictoria** (a menudo **poco fiables**) que **resuenan** con nuestra coherencia en **decisiones más sólidas** mediante **rituales de coherencia** (precompromisos, historias rivales, actualización antes/después, doble columna resuena/fiable), sin depender de **métricas** ni _dashboards_.

### Experimentos con fricción útil en producto

- **Precompromiso**: formular la **pregunta decisiva** y el si-entonces: “Si observamos señales **(S1 y S2)** (cualitativas y trazables), **integramos** la novedad; si aparecen **(R1 o R2)** (riesgos/daños), **revertimos**”.
  - **p. ej.:** Si (abandono en “verificación” baja **20% relativo** en 2 sprints **y** 5/10 entrevistas mencionan menor confusión) → **integrar**; si (tickets “no entiendo la verificación” **≥5/semana** durante 2 semanas **o** tasa de errores **>1% por transacción** durante 7 días) → **revertir**.
- **Historias rivales:** redactar la **mejor** versión del argumento a favor y en contra; **antes de debatir, fija por escrito criterios simétricos** para ambos (p. ej., **población**, **métrica**, **ventana temporal**, **umbral de éxito**, **horizonte de revisión**, **riesgos aceptables**).

- **Señales de activación** (no numéricas): ejemplos de comportamientos de usuario, objeciones en soporte, patrones de abandono narrados, fricciones recurrentes en entrevistas.
  - Usuarios dicen “no entiendo la verificación” al abandonar ese paso.
  - En soporte aparece repetido “no encuentro dónde cambiar la contraseña”.
- **Ventana de revisión**: fecha fija (p. ej., 2 semanas) para evaluar **antes/después** por escrito.

### Post-mortems sin culpa

- **Separación de planos**: (a) *qué cambió* (hechos narrables/trazables); (b) *por qué decidimos así*(contexto/limitaciones); (c) *qué actualizar* (reglas, diccionario de términos, criterios si-entonces).
- **Registro de contraevidencia**: lista de piezas que **no encajan** pero podrían indicar aprendizaje; asignar responsables de seguimiento.
- **Lenguaje de actualización**: “A la luz de X e Y, **actualizamos** Z; si aparece W, **revisamos** de nuevo”.

### Decisiones de arquitectura

- **Riesgo de disonancia**: la opción que **resuena** con la identidad del equipo ("somos _microservices_" / "aquí todo es síncrono por simplicidad") puede imponerse pese a **señales contradictorias** del contexto.
- **Ritual**: **RFC con** *steelman* de la alternativa descartada; **criterios invariantes** definidos antes de debatir (acoplamiento real, límites de dominio, ritmo de entrega, capacidad operativa, radio de fallo, latencia de extremo a extremo). **Precompromiso** con mapa si-entonces y **stop-loss cognitivo**.
- **Señales S (integrar)**: menos *handoffs* entre equipos, despliegues más simples, límites de contexto estables, menor coordinación para cambios pequeños.
- **Señales R (revisar/revertir)**: **creep** de dependencias cruzadas, cascadas de fallos, coordinación creciente por cambios pequeños, proliferación de excepciones _ad hoc_.

### Priorización de backlog con señales contradictorias

- **Caso**: “este *feature* es **clave** para _enterprise_” (rumor que **cuadra** pero es poco fiable).
- **Ritual**: **regla de 3 fuentes** (ventas, soporte, investigación de usuario) + **entrevistas rápidas** (5 clientes) con *steelman* de la objeción; **contrafactual mínimo viable**: ¿qué pasa si *no* lo hacemos 2 sprints?
- **Decisión condicional**: si aparecen S1/S2 (patrones de abandono narrados, objeciones repetidas trazables), **integrar**; si no, **posponer** y revisar fecha.

### Code review: preferencias identitarias vs. criterio técnico

- **Riesgo**: confundir **gusto** con **criterio** (p. ej., estilo de framework vs. claridad/seguridad).
- **Ritual**: plantilla de PR con tres bloques: (a) **riesgo adverso** contemplado, (b) **qué cambiaría** mi opinión, (c) *steelman* de la alternativa. **Semáforo de afirmaciones** (verde=hecho trazable, ámbar=inferencia, rojo=rumor/coherencia sin base). **Doble columna** *resuena / es fiable*.

# 7. Fuentes y lecturas recomendadas

- Festinger, L. *Teoría de la disonancia cognoscitiva* (1957).
- Bartra, R. *Antropología del cerebro: conciencia, cultura y libre albedrío* (2014).
- Gelman, A. & Loken, E. *The garden of forking paths* (ensayo sobre decisiones analíticas y significación).
- Kahneman, D. *Thinking, Fast and Slow* (visiones prácticas sobre sesgos e incertidumbre).
- McElreath, R. *Statistical Rethinking* (enfoque aplicado y explícito sobre incertidumbre y actualización).
